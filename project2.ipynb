{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudjwissa/Project-2-Retail-Sales-Analytics-and-Real-Time-Demand-Forecasting/blob/main/project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pyspark setup\n",
        "\n",
        "!apt-get update\n",
        "# Install Java 8 (required by Spark)\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Install Spark\n",
        "!pip install pyspark\n",
        "\n",
        "# setup environment variables\n",
        "import os\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/usr/local/lib/python3.10/dist-packages/pyspark\""
      ],
      "metadata": {
        "id": "PT0QftQ2CSln",
        "outputId": "b2040a68-7ee3-454f-f5b4-8eb184dd7fd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connected to r2u.stat.illinois.edu (192\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8JxMYZThCOtL"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import TimestampType\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Project2\").getOrCreate()\n",
        "\n",
        "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
        "\n",
        "output_dir = \"output/\"\n",
        "task2_output_total = output_dir + \"task2/task2_total.csv\"\n",
        "task2_output_avgsales = output_dir + \"task2/task2_avgsales.csv\"\n",
        "task2_output_season = output_dir + \"task2/task2_season.csv\"\n",
        "task3_output = output_dir + \"task3/task3.csv\"\n",
        "task4_output = output_dir + \"task4/task4.csv\"\n",
        "\n",
        "checkpoint_dir = \"checkpoint/task5/\"\n",
        "task5_output = output_dir + \"task5.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lbXIfGxXCOtN",
        "outputId": "db4cf708-e4bf-4ba3-b91b-a5bbbe3ee3d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+--------------------+--------------------+--------------------+\n",
            "|      asin|helpful|      main_image_url|       product_title|            sentence|\n",
            "+----------+-------+--------------------+--------------------+--------------------+\n",
            "|B000AO3L84|    1.7|http://ecx.images...|Canon 430EX Speed...|this flash is a s...|\n",
            "|B001SEQPGK|    1.3|http://ecx.images...|Sony Cyber-shot D...|The pictures were...|\n",
            "|0553386697|    1.9|http://ecx.images...|The Whole-Brain C...|A very good resou...|\n",
            "|B006SUWZH2|   0.25|http://ecx.images...|Memorex Portable ...|We have it in a c...|\n",
            "|B000W7F5SS|    0.9|http://ecx.images...|Harry Potter and ...|Again the makers ...|\n",
            "|B000AO3L84|    2.0|http://ecx.images...|Canon 430EX Speed...|This flash is a g...|\n",
            "|B00081NX5U|   0.73|http://ecx.images...|iPod Detachable R...|So I've had these...|\n",
            "|B00000F1D3|    0.9|http://ecx.images...|             Believe|they're cd's or t...|\n",
            "|B00000FCBH|    1.3|http://ecx.images...|  2Pac Greatest Hits|he proved that ev...|\n",
            "|B00013M6NU|    0.4|http://ecx.images...|Nikon MH-61 Batte...|I realize these t...|\n",
            "|0375703764|    1.5|http://ecx.images...|     House of Leaves|Emulate contortio...|\n",
            "|B000002GJH|    0.9|http://ecx.images...|   Temple Of The Dog|The best tracks i...|\n",
            "|B002JSM3KQ|    0.2|http://ecx.images...|Monopoly Board Ga...|, so Amazon likes...|\n",
            "|B008FSCNTK|    0.4|http://ecx.images...|       Glad Rag Doll|but I'll be check...|\n",
            "|B003T90WY8|    1.7|http://ecx.images...|EARBUDi Clips on ...|Edit to add: Thes...|\n",
            "|B00002E220|    0.8|http://ecx.images...|  Last of the Dogmen|I had the VHS and...|\n",
            "|B0002COTDA|    1.0|http://ecx.images...|Columbo - The Com...|Columbo is one of...|\n",
            "|0061208493|   1.36|http://ecx.images...|The Complete C. S...|any of his books ...|\n",
            "|B000002KB8|    1.0|http://ecx.images...|       Black Sabbath|The title has not...|\n",
            "|0470474874|    1.1|http://ecx.images...|    Excel 2010 Bible|It basically copi...|\n",
            "+----------+-------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_df = spark.read.json(\"train.json\")\n",
        "reviwes_df = spark.read.json(\"test.json\")\n",
        "train_df.show()\n",
        "#reviwes_df = reviwes_df.withColumn(\"helpful\", F.col(\"helpful\").cast(\"double\"))\n",
        "#reviwes_df.printSchema()\n",
        "#print(reviwes_df.describe())\n",
        "# Check if any rows have nulls in the 'helpful' column after casting\n",
        "#invalid_rows = reviwes_df.filter(F.col(\"sentence\").isNull())\n",
        "# Show rows that could not be cast to double\n",
        "#invalid_rows.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mJ3EiGojCOtO",
        "outputId": "6e9333a7-9776-433e-acd7-dc78e6d812fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+--------------------+--------------------+--------------------+\n",
            "|      asin|helpful|      main_image_url|       product_title|            sentence|\n",
            "+----------+-------+--------------------+--------------------+--------------------+\n",
            "|B00VG90446|   1.07|http://ecx.images...|Flexion KS-902 Ki...|so it stays in pl...|\n",
            "|B001196MG0|   1.33|http://ecx.images...|Savage 107X12-1 S...|Love this seamles...|\n",
            "|B00081NX5U|   1.17|http://ecx.images...|iPod Detachable R...|very happy with m...|\n",
            "|B003HC9JIW|    1.6|http://ecx.images...|Start! Walking At...|Even for someone ...|\n",
            "|B00C30FCUI|   1.49|http://ecx.images...|Symphonized NRG P...|, those have alwa...|\n",
            "|B001196MG0|   1.47|http://ecx.images...|Savage 107X12-1 S...|but after a year ...|\n",
            "|B00AR1G3FS|   1.24|http://ecx.images...|Farewell Live Fro...|While not quite a...|\n",
            "|B007R3AZNK|   0.67|http://ecx.images...|Driving Towards T...|Until now, Sloe G...|\n",
            "|0761165975|    1.0|http://ecx.images...|The Wedding Plann...|I considered the ...|\n",
            "|B00000FCBH|   0.03|http://ecx.images...|  2Pac Greatest Hits|\"Baby, don't cry,...|\n",
            "|B000HKDE7Y|   0.74|http://ecx.images...|Struggle From The...|I'm glad I bought...|\n",
            "|B00081NX5U|   1.59|http://ecx.images...|iPod Detachable R...|Great sound I bou...|\n",
            "|0451232852|    0.5|http://ecx.images...|Fall of Giants: B...|The Age of Enligh...|\n",
            "|B000AO3L84|   1.66|http://ecx.images...|Canon 430EX Speed...|When you take pic...|\n",
            "|B000002IAO|   0.75|http://ecx.images...|  In-A-Gadda-Da-Vida|There were times ...|\n",
            "|B000002GJH|   0.37|http://ecx.images...|   Temple Of The Dog|Grunge can't just...|\n",
            "|0671015206|   1.03|http://ecx.images...|The Millionaire N...|Worth Skipping, o...|\n",
            "|0670012335|   0.31|http://ecx.images...|Llama Llama Time ...|This was a Christ...|\n",
            "|B0019FHM9M|   0.39|http://ecx.images...|Lowpricenice MH20...|-----------------...|\n",
            "|0399162089|   1.13|http://ecx.images...|Outside the Lines...|I couldn't make t...|\n",
            "+----------+-------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "reviwes_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RcoXZmtGCOtO"
      },
      "outputs": [],
      "source": [
        "online_retail_df = spark.read.csv(\"Online-Retail.csv\", inferSchema=True, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XBSBIBD2COtO",
        "outputId": "7b874ec5-b5e7-4a9b-e7b6-adffb37d5e51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
            "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
            "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
            "|        0|        0|       1454|       0|          0|        0|    135080|      0|\n",
            "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "online_retail_df.select([F.count(F.when(col(c).isNull(), c)).alias(c) for c in online_retail_df.columns]).show()\n",
        "\n",
        "# Drop rows with nulls in important columns like CustomerID, Description, etc.\n",
        "online_retail_df = online_retail_df.dropna(subset=[\"CustomerID\", \"Description\", \"InvoiceDate\", \"Quantity\", \"UnitPrice\"])\n",
        "#online_retail_df.select([F.count(F.when(col(c).isNull(), c)).alias(c) for c in online_retail_df.columns]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Cwa7m6a1COtP"
      },
      "outputs": [],
      "source": [
        "#drop duplicates\n",
        "online_retail_df = online_retail_df.dropDuplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hhaNUv55COtP"
      },
      "outputs": [],
      "source": [
        "#cast the invoice date to timestamp\n",
        "online_retail_df = online_retail_df.withColumn(\"InvoiceDate\", F.to_timestamp(\"InvoiceDate\", \"M/d/yyyy H:mm\"))\n",
        "online_retail_df = online_retail_df.withColumn(\"InvoiceDate\", F.col(\"InvoiceDate\").cast(TimestampType()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EwS8wuXzCOtP",
        "outputId": "7b0506c1-213b-4d77-b721-3bb3ef19cb2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "|  C538350|   85099F|JUMBO BAG STRAWBERRY|      -2|2010-12-10 15:01:00|     1.65|     13798|United Kingdom|\n",
            "|  C538375|    22220|CAKE STAND LOVEBI...|      -1|2010-12-12 11:19:00|     9.95|     17126|United Kingdom|\n",
            "|  C539726|    22791|T-LIGHT GLASS FLU...|     -10|2010-12-21 14:24:00|     1.25|     17007|United Kingdom|\n",
            "|  C540307|    22084|PAPER CHAIN KIT E...|     -36|2011-01-06 12:58:00|     2.95|     15823|United Kingdom|\n",
            "|  C542138|    20866|BLUE ROSE FABRIC ...|    -120|2011-01-25 17:21:00|     1.06|     17368|United Kingdom|\n",
            "|  C543347|    22629| SPACEBOY LUNCH BOX |      -1|2011-02-07 12:44:00|     1.95|     12472|       Germany|\n",
            "|  C544830|    22059|CERAMIC STRAWBERR...|      -6|2011-02-24 09:59:00|     1.49|     13118|United Kingdom|\n",
            "|  C545456|    21527|RED RETROSPOT TRA...|      -1|2011-03-02 17:15:00|     7.95|     17865|United Kingdom|\n",
            "|  C545773|    21843|RED RETROSPOT CAK...|      -1|2011-03-07 12:06:00|    10.95|     17139|United Kingdom|\n",
            "|  C546168|    22892|SET OF SALT AND P...|     -12|2011-03-10 10:22:00|     1.25|     16670|United Kingdom|\n",
            "|  C546511|    22801|ANTIQUE GLASS PED...|      -1|2011-03-14 12:19:00|     3.75|     12921|United Kingdom|\n",
            "|  C548015|    82583|HOT BATHS METAL SIGN|     -30|2011-03-29 11:30:00|     1.69|     13802|United Kingdom|\n",
            "|  C548187|    22423|REGENCY CAKESTAND...|      -1|2011-03-29 15:06:00|    12.75|     17511|United Kingdom|\n",
            "|  C550423|    23052|RECYCLED ACAPULCO...|      -1|2011-04-18 12:06:00|     8.25|     14403|United Kingdom|\n",
            "|  C551140|    48194|      DOORMAT HEARTS|      -1|2011-04-26 13:11:00|     7.95|     17613|United Kingdom|\n",
            "|  C553667|    84816|DANISH ROSE BEDSI...|      -1|2011-05-18 12:21:00|    39.95|     14755|United Kingdom|\n",
            "|  C554848|    21642|ASSORTED TUTTI FR...|     -12|2011-05-26 19:56:00|     0.85|     13659|United Kingdom|\n",
            "|  C559049|    23079|TOADSTOOL BEDSIDE...|      -2|2011-07-05 15:50:00|     8.95|     12494|        France|\n",
            "|  C562952|    22981|  PANTRY APPLE CORER|      -5|2011-08-11 10:10:00|     1.45|     12749|United Kingdom|\n",
            "|  C542642|    22720|SET OF 3 CAKE TIN...|      -1|2011-01-31 11:27:00|     4.95|     15827|United Kingdom|\n",
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#check for outliers\n",
        "online_retail_df.filter((col(\"Quantity\") < 0) | (col(\"UnitPrice\") < 0)).show()\n",
        "\n",
        "# Drop rows where Quantity or UnitPrice are negative (common outlier check)\n",
        "online_retail_df = online_retail_df.filter((F.col(\"Quantity\") >= 0) & (F.col(\"UnitPrice\") >= 0))\n",
        "#online_retail_df.filter((col(\"Quantity\") < 0) | (col(\"UnitPrice\") < 0)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "L9Mm2ooFCOtQ"
      },
      "outputs": [],
      "source": [
        "#standardize for consistent description characters\n",
        "online_retail_df = online_retail_df.withColumn(\"Description\", F.upper(F.col(\"Description\")))\n",
        "\n",
        "#handle special cases in case for better performance for MLlib\n",
        "#online_retail_df = online_retail_df.filter(~F.col(\"InvoiceNo\").startswith(\"C\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vpWSl4XlCOtQ",
        "outputId": "107911ae-2aae-46e7-f1d3-c634031f328a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|     13047|United Kingdom|\n",
            "|   536368|    22960|JAM MAKING SET WI...|       6|2010-12-01 08:34:00|     4.25|     13047|United Kingdom|\n",
            "|   536388|    22915|ASSORTED BOTTLE T...|      12|2010-12-01 09:59:00|     0.42|     16250|United Kingdom|\n",
            "|   536401|    21464|DISCO BALL ROTATO...|       1|2010-12-01 11:21:00|     4.25|     15862|United Kingdom|\n",
            "|   536412|    22569|FELTCRAFT CUSHION...|       2|2010-12-01 11:49:00|     3.75|     17920|United Kingdom|\n",
            "|   536425|    22645|CERAMIC HEART FAI...|      12|2010-12-01 12:08:00|     1.45|     13758|United Kingdom|\n",
            "|   536488|    22376|AIRLINE BAG VINTA...|       1|2010-12-01 12:31:00|     4.25|     17897|United Kingdom|\n",
            "|   536520|    21930|JUMBO STORAGE BAG...|       1|2010-12-01 12:43:00|     1.95|     14729|United Kingdom|\n",
            "|   536534|    22866|HAND WARMER SCOTT...|      12|2010-12-01 13:33:00|      2.1|     15350|United Kingdom|\n",
            "|   536540|   85136A|YELLOW SHARK HELI...|       2|2010-12-01 14:05:00|     7.95|     14911|          EIRE|\n",
            "|   536562|   79302M|ART LIGHTS,FUNK M...|       6|2010-12-01 15:08:00|     2.95|     13468|United Kingdom|\n",
            "|   536569|    22941|CHRISTMAS LIGHTS ...|       1|2010-12-01 15:35:00|      8.5|     16274|United Kingdom|\n",
            "|   536571|    21352|EUCALYPTUS & PINE...|       2|2010-12-01 15:37:00|     6.75|     14696|United Kingdom|\n",
            "|   536591|    21985|PACK OF 12 HEARTS...|       4|2010-12-01 16:58:00|     0.29|     14606|United Kingdom|\n",
            "|   536624|    22672|FRENCH BATHROOM S...|      12|2010-12-02 10:45:00|     1.65|     13418|United Kingdom|\n",
            "|   536624|    21843|RED RETROSPOT CAK...|       4|2010-12-02 10:45:00|    10.95|     13418|United Kingdom|\n",
            "|   536630|    22752|SET 7 BABUSHKA NE...|       2|2010-12-02 10:56:00|     7.65|     17850|United Kingdom|\n",
            "|   536635|    22441|GROW YOUR OWN BAS...|       8|2010-12-02 11:22:00|      2.1|     15955|United Kingdom|\n",
            "|   536667|    22594|CHRISTMAS GINGHAM...|      24|2010-12-02 12:09:00|     0.85|     15260|United Kingdom|\n",
            "|   536671|    22740|        POLKADOT PEN|      48|2010-12-02 12:10:00|     0.85|     13305|United Kingdom|\n",
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "online_retail_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HSA5gyWuCOtR",
        "outputId": "4f1daadb-004a-437a-f4ca-45997433ca4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+-----+----+------------------+\n",
            "|StockCode|         Description|Month|Year|        TotalSales|\n",
            "+---------+--------------------+-----+----+------------------+\n",
            "|    22692|DOORMAT WELCOME T...|    4|2011| 512.6999999999999|\n",
            "|    84945|MULTI COLOUR SILV...|    5|2011| 791.5799999999999|\n",
            "|    22384|LUNCH BAG PINK PO...|    1|2011| 902.1500000000001|\n",
            "|    21221|SET/4 BADGES CUTE...|    2|2011|             43.75|\n",
            "|   47591D|PINK FAIRY CAKE C...|    5|2011| 601.8000000000002|\n",
            "|    22114|HOT WATER BOTTLE ...|   12|2010|1863.0500000000002|\n",
            "|    22236|CAKE STAND 3 TIER...|    1|2011|403.04999999999995|\n",
            "|    22407|MONEY BOX FIRST A...|    4|2011|             18.75|\n",
            "|    20768| GREEN FERN JOURNAL |    7|2011|              35.7|\n",
            "|    85213|MINI  ZINC GARDEN...|    3|2011|44.199999999999996|\n",
            "|    20981|12 PENCILS TALL T...|    6|2011|25.499999999999996|\n",
            "|    84828|JUNGLE POPSICLES ...|    7|2011|             112.5|\n",
            "|    22624|IVORY KITCHEN SCALES|    3|2011|            779.45|\n",
            "|    20914|SET/5 RED RETROSP...|    3|2011| 962.6499999999999|\n",
            "|    21617|4 LILY  BOTANICAL...|    6|2011|             33.75|\n",
            "|    23343|JUMBO BAG VINTAGE...|    7|2011|            149.76|\n",
            "|    84929|ASSTD FRUIT+FLOWE...|    7|2011|150.00000000000003|\n",
            "|    21051|      RIBBONS PURSE |   12|2010|              33.6|\n",
            "|   85188A|GREEN METAL SWING...|    4|2011|23.799999999999997|\n",
            "|    23041|PAPER LANTERN 9 P...|    6|2011| 41.50000000000001|\n",
            "+---------+--------------------+-----+----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#-----------------------------------\n",
        "#Task 2: Sales Data Aggregation and Feature Engineering\n",
        "#-----------------------------------\n",
        "#total sales per product per month\n",
        "#get the month and year from invoicedate\n",
        "online_retail_df = online_retail_df.withColumn(\"Month\", F.month(\"InvoiceDate\")).withColumn(\"Year\", F.year(\"InvoiceDate\"))\n",
        "\n",
        "#make a revenue column, total quantity * price\n",
        "online_retail_df = online_retail_df.withColumn(\"Revenue\", col(\"Quantity\") * col(\"UnitPrice\"))\n",
        "\n",
        "#total sales per product and month. calculated by summing total quantity * price\n",
        "total_sales_df = online_retail_df.groupBy(\"StockCode\", \"Description\", \"Month\", \"Year\").agg(F.sum(\"Revenue\").alias(\"TotalSales\"))\n",
        "total_sales_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bumJEnHzCOtS",
        "outputId": "c142b286-897e-44d7-cb6c-8486e6e29df6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+\n",
            "|CustomerID|    AverageRevenue|\n",
            "+----------+------------------+\n",
            "|     12346|           77183.6|\n",
            "|     16446|           56157.5|\n",
            "|     15098|           13305.5|\n",
            "|     15749|           4453.43|\n",
            "|     15195|            3861.0|\n",
            "|     13135|            3096.0|\n",
            "|     17846|            2033.1|\n",
            "|     18087|2027.8599999999997|\n",
            "|     16532|            1687.2|\n",
            "|     16000|1377.0777777777778|\n",
            "|     16754|            1001.2|\n",
            "|     12755| 952.9874999999998|\n",
            "|     18133| 931.4999999999999|\n",
            "|     12798| 872.1299999999999|\n",
            "|     17949| 835.8640000000001|\n",
            "|     17553|             743.8|\n",
            "|     15299| 643.8585714285715|\n",
            "|     16308|             640.0|\n",
            "|     16986|             624.4|\n",
            "|     18080|            615.75|\n",
            "+----------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#average revenue per customer\n",
        "#get average revnue for each customer id\n",
        "avg_revnue_df = online_retail_df.groupBy(\"CustomerID\").agg(F.avg(\"Revenue\").alias(\"AverageRevenue\")).orderBy(F.desc(\"AverageRevenue\"))\n",
        "avg_revnue_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zId1LgaVCOtS",
        "outputId": "90e48550-2741-4e0c-dc2c-6eb76f4b1ea1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+-----+------------------+\n",
            "|StockCode|         Description|Month|      MonthlySales|\n",
            "+---------+--------------------+-----+------------------+\n",
            "|   85123A|WHITE HANGING HEA...|    4| 9581.649999999998|\n",
            "|    84879|ASSORTED COLOUR B...|    1| 2704.189999999999|\n",
            "|    23166|MEDIUM CERAMIC TO...|    9|            397.26|\n",
            "|    47566|       PARTY BUNTING|    1|1815.1499999999999|\n",
            "|        M|              MANUAL|    8|           2989.54|\n",
            "|    23084|  RABBIT NIGHT LIGHT|    9|            235.14|\n",
            "|   85123A|WHITE HANGING HEA...|    2| 4912.650000000001|\n",
            "|   85099B|JUMBO BAG RED RET...|   10| 9763.060000000005|\n",
            "|    22423|REGENCY CAKESTAND...|    1|10765.499999999998|\n",
            "|   85099B|JUMBO BAG RED RET...|    7|            5654.6|\n",
            "|     POST|             POSTAGE|   11|          10349.95|\n",
            "|    47566|       PARTY BUNTING|   11|3715.7099999999996|\n",
            "|   85123A|WHITE HANGING HEA...|   11|13849.929999999993|\n",
            "|    47566|       PARTY BUNTING|    9|            4387.0|\n",
            "|     POST|             POSTAGE|    2|            3166.0|\n",
            "|   85123A|WHITE HANGING HEA...|    8|5498.0999999999985|\n",
            "|        M|              MANUAL|   12|            666.27|\n",
            "|    84879|ASSORTED COLOUR B...|    3|3997.9799999999987|\n",
            "|    47566|       PARTY BUNTING|    8| 6306.050000000001|\n",
            "|    22423|REGENCY CAKESTAND...|    6| 8216.349999999999|\n",
            "+---------+--------------------+-----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#seasonal patterns for top selling products\n",
        "#get products by stock code and their highest total revnue as sum\n",
        "top_products_df = online_retail_df.groupBy(\"StockCode\").agg(F.sum(\"Revenue\").alias(\"TotalRevenue\")).orderBy(F.desc(\"TotalRevenue\"))\n",
        "\n",
        "#join with df to get montly data, group by product and month for each of their total revenue\n",
        "seasonal_pattern = online_retail_df.join(top_products_df.limit(10), \"StockCode\").groupBy(\"StockCode\", \"Description\", \"Month\").agg(F.sum(\"Revenue\").alias(\"MonthlySales\"))\n",
        "seasonal_pattern.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6BTIdlGsCOtT",
        "outputId": "a99204d1-008c-432b-b277-d0df0a79269d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+---------------------+\n",
            "|CustomerID|StockCode|CustomerLifetimeValue|\n",
            "+----------+---------+---------------------+\n",
            "|     15363|    22382|                 16.5|\n",
            "|     15498|    22749|                 15.0|\n",
            "|     17530|    22557|   28.049999999999997|\n",
            "|     17841|    22554|                57.75|\n",
            "|     17730|   71101E|                 10.2|\n",
            "|     17581|   85099B|                405.5|\n",
            "|     16271|   85123A|                 64.9|\n",
            "|     17235|   85184C|   35.400000000000006|\n",
            "|     14156|    22927|                 71.4|\n",
            "|     17501|    21977|   13.200000000000001|\n",
            "|     15555|    21793|   11.850000000000001|\n",
            "|     16327|    22355|                 32.3|\n",
            "|     15382|    23282|                34.86|\n",
            "|     13700|    22661|               144.25|\n",
            "|     17454|    21931|                 19.5|\n",
            "|     13113|    22423|                700.8|\n",
            "|     16656|    21790|    777.5999999999999|\n",
            "|     13933|    23198|                 17.4|\n",
            "|     13451|    21179|                 2.34|\n",
            "|     14498|    22457|                 11.8|\n",
            "+----------+---------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#customer liftime value: total revenue per customer\n",
        "clv_df = online_retail_df.groupBy(\"CustomerID\", \"StockCode\").agg(F.sum(\"Revenue\").alias(\"CustomerLifetimeValue\"))\n",
        "clv_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Wvha2JQWCOtT",
        "outputId": "a3923c2b-32e8-42de-ccdd-fc1cd0386ad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------------+\n",
            "|StockCode|PopularityScore|\n",
            "+---------+---------------+\n",
            "|    21889|            449|\n",
            "|    21259|            237|\n",
            "|    22728|            613|\n",
            "|    21452|            133|\n",
            "|    22121|            114|\n",
            "|    21894|             71|\n",
            "|    90143|              7|\n",
            "|    22596|            234|\n",
            "|    84881|              5|\n",
            "|    21248|             52|\n",
            "|    22254|             41|\n",
            "|    21249|             79|\n",
            "|    23318|            329|\n",
            "|   90026D|              3|\n",
            "|    90022|              4|\n",
            "|    21331|              7|\n",
            "|    23459|             19|\n",
            "|    20868|             31|\n",
            "|   90210B|              6|\n",
            "|    23843|              1|\n",
            "+---------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#product popularity: counted by unique transaction made under each stock code\n",
        "product_popularity = online_retail_df.groupBy(\"StockCode\").agg(F.countDistinct(\"InvoiceNo\").alias(\"PopularityScore\"))\n",
        "product_popularity.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tCdZXFpcCOtT",
        "outputId": "9ee7841e-71a8-44a1-eebd-5bac096053fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------+------------------+\n",
            "|StockCode|Season|     SeasonalSales|\n",
            "+---------+------+------------------+\n",
            "|    21110|Winter|            1349.3|\n",
            "|    22668|Winter|            1411.7|\n",
            "|    23203|Summer|15717.460000000015|\n",
            "|    21213|Summer|1750.9500000000005|\n",
            "|    21371|Summer|             129.0|\n",
            "|    22728|Summer|           4546.26|\n",
            "|    22966|Winter|2459.8599999999997|\n",
            "|   90002D|Winter|              30.0|\n",
            "|    22149|Spring|            2487.7|\n",
            "|    22661|Summer|1333.0500000000002|\n",
            "|    22089|Summer| 926.7500000000002|\n",
            "|    37446|Winter| 659.5999999999999|\n",
            "|    22252|Spring|             97.94|\n",
            "|    22760|Winter|             849.9|\n",
            "|   84558A|Winter|268.45000000000005|\n",
            "|    22421|Winter|            159.48|\n",
            "|    22301|Winter|1107.4499999999998|\n",
            "|    22537|Spring|            190.26|\n",
            "|    23147|Summer|1035.2999999999995|\n",
            "|    16219|Summer|197.99999999999997|\n",
            "+---------+------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#seasonal trends:\n",
        "#make season column based on month\n",
        "online_retail_df = online_retail_df.withColumn(\"Season\",\n",
        "                    F.when(col(\"Month\").isin(12, 1, 2), \"Winter\") #if month is in one of these numbers\n",
        "                    .when(col(\"Month\").isin(3, 4, 5), \"Spring\")\n",
        "                    .when(col(\"Month\").isin(6, 7, 8), \"Summer\")\n",
        "                    .when(col(\"Month\").isin(9, 10, 11), \"Fall\")\n",
        "                    )\n",
        "\n",
        "#total revenue of each product and season\n",
        "seasonal_trends = online_retail_df.groupBy(\"StockCode\", \"Season\").agg(F.sum(\"Revenue\").alias(\"SeasonalSales\"))\n",
        "seasonal_trends.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qGlO86gjCOtU"
      },
      "outputs": [],
      "source": [
        "#write the aggregated data to the directory as csv files\n",
        "#try:\n",
        "#    total_sales_df.write.csv(task2_output_total, header=True)\n",
        "#    avg_revnue_df.write.csv(task2_output_avgsales, header=True)\n",
        "#    seasonal_pattern.write.csv(task2_output_season, header=True)\n",
        "#except ValueError as e:\n",
        "#    print(f\"error {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mMEEW5-KCOtU"
      },
      "outputs": [],
      "source": [
        "# Join features into a consolidated DataFrame\n",
        "forecasting_df = total_sales_df.join(clv_df, \"StockCode\", \"left\") \\\n",
        "                               .join(product_popularity, \"StockCode\", \"left\") \\\n",
        "                               .join(seasonal_trends, \"StockCode\", \"left\")\n",
        "\n",
        "# Fill nulls with 0 or appropriate values for ML training\n",
        "forecasting_df = forecasting_df.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tJFpM5JbCOtU",
        "outputId": "e2b7ab0b-33d2-45e5-e75a-c647146b15d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+-----+----+------------------+----------+---------------------+---------------+------+------------------+------------------+------------------+\n",
            "|StockCode|         Description|Month|Year|        TotalSales|CustomerID|CustomerLifetimeValue|PopularityScore|Season|     SeasonalSales|       Lag_1_Month|      Lag_2_Months|\n",
            "+---------+--------------------+-----+----+------------------+----------+---------------------+---------------+------+------------------+------------------+------------------+\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     17967|                 0.85|             49|Winter| 519.3499999999999|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     17967|                 0.85|             49|Spring|180.20000000000002|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     17337|                  1.7|             49|Winter| 519.3499999999999|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     17337|                  1.7|             49|Spring|180.20000000000002|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     14525|                 0.85|             49|Winter| 519.3499999999999|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     14525|                 0.85|             49|Spring|180.20000000000002|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     16395|                  5.1|             49|Winter| 519.3499999999999|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     16395|                  5.1|             49|Spring|180.20000000000002|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     12731|                234.6|             49|Winter| 519.3499999999999|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     12731|                234.6|             49|Spring|180.20000000000002|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     16701|                 20.4|             49|Winter| 519.3499999999999|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     16701|                 20.4|             49|Spring|180.20000000000002|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     15382|                 10.2|             49|Winter| 519.3499999999999|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     15382|                 10.2|             49|Spring|180.20000000000002|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     12673|                 0.85|             49|Winter| 519.3499999999999|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     12673|                 0.85|             49|Spring|180.20000000000002|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     15514|                  1.7|             49|Winter| 519.3499999999999|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     15514|                  1.7|             49|Spring|180.20000000000002|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     12681|                 10.2|             49|Winter| 519.3499999999999|190.39999999999998|190.39999999999998|\n",
            "|    10002|INFLATABLE POLITI...|   12|2010|190.39999999999998|     12681|                 10.2|             49|Spring|180.20000000000002|190.39999999999998|190.39999999999998|\n",
            "+---------+--------------------+-----+----+------------------+----------+---------------------+---------------+------+------------------+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create lag features using window functions\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "windowSpec = Window.partitionBy(\"StockCode\").orderBy(\"Year\", \"Month\")\n",
        "forecasting_df = forecasting_df.withColumn(\"Lag_1_Month\", F.lag(\"TotalSales\", 1).over(windowSpec))\n",
        "forecasting_df = forecasting_df.withColumn(\"Lag_2_Months\", F.lag(\"TotalSales\", 2).over(windowSpec))\n",
        "\n",
        "# Drop rows with null values created by lags\n",
        "forecasting_df = forecasting_df.na.drop()\n",
        "\n",
        "# Display the consolidated DataFrame structure\n",
        "forecasting_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forecasting_df.printSchema()"
      ],
      "metadata": {
        "id": "Mw1WV6x_SHGP",
        "outputId": "0773ad33-c868-40b6-a261-d8fd84cc06f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- StockCode: string (nullable = true)\n",
            " |-- Description: string (nullable = true)\n",
            " |-- Month: integer (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- TotalSales: double (nullable = false)\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- CustomerLifetimeValue: double (nullable = false)\n",
            " |-- PopularityScore: long (nullable = true)\n",
            " |-- Season: string (nullable = true)\n",
            " |-- SeasonalSales: double (nullable = false)\n",
            " |-- Lag_1_Month: double (nullable = true)\n",
            " |-- Lag_2_Months: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "M1NHm33RCOtU"
      },
      "outputs": [],
      "source": [
        "# Assemble feature columns\n",
        "feature_cols = [\"Lag_1_Month\", \"Lag_2_Months\", \"CustomerLifetimeValue\", \"PopularityScore\", \"SeasonalSales\"]\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
        "                        # Handles outliers or infinite values by replacing them with mean/median\n",
        "                        withMean=True, withStd=True)\n",
        "\n",
        "# Initialize the regression model (e.g., Linear Regression)\n",
        "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"TotalSales\")\n",
        "\n",
        "# Create a pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[assembler, scaler, lr])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, isnan, col as pyspark_col\n",
        "# Import necessary types for type checking\n",
        "from pyspark.sql.types import IntegerType, FloatType, DoubleType\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_data, test_data = forecasting_df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Before fitting, ensure data types are correct and handle potential issues\n",
        "# Check if columns have numerical types (e.g. int, float)\n",
        "for column_name in feature_cols + [\"TotalSales\"]: # Changed 'col' to 'column_name'\n",
        "    data_type = train_data.schema[column_name].dataType\n",
        "    if not isinstance(data_type, (IntegerType, FloatType, DoubleType)):\n",
        "        print(f\"Column '{column_name}' has an unexpected type: {data_type}. Consider casting it to a numerical type.\")\n",
        "\n",
        "# Handle NaNs and infinite values\n",
        "for column_name in feature_cols + [\"TotalSales\"]: # Changed 'col_name' to 'column_name'\n",
        "    # Use pyspark.sql.functions.col to refer to the column\n",
        "    # Avoid using 'col' as a variable name, use 'pyspark_col' instead\n",
        "    # Rename the imported 'col' function to 'pyspark_col' to avoid conflicts\n",
        "    train_data = train_data.withColumn(\n",
        "        column_name,\n",
        "        when(isnan(pyspark_col(column_name)) | (pyspark_col(column_name) == float(\"inf\")) | (pyspark_col(column_name) == float(\"-inf\")), 0).otherwise(pyspark_col(column_name))\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = RegressionEvaluator(labelCol=\"TotalSales\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "mae = evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"})\n",
        "\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")"
      ],
      "metadata": {
        "id": "O-CWhCpNP_-V",
        "outputId": "2d28f544-da9a-4293-9e86-d1b2d355735d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'PopularityScore' has an unexpected type: LongType(). Consider casting it to a numerical type.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Exception while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\", line 179, in deco\n",
            "    return f(*a, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\", line 326, in get_return_value\n",
            "    raise Py4JJavaError(\n",
            "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 516, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 539, in send_command\n",
            "    raise Py4JNetworkError(\n",
            "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Py4JError",
          "evalue": "py4j.reflection.TypeUtil.isInstanceOf does not exist in the JVM",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(111, 'Connection refused'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-eea77e1db938>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnknownException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mconvert_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_instance_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"org.apache.spark.sql.streaming.StreamingQueryException\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mStreamingQueryException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mis_instance_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"org.apache.spark.sql.execution.QueryExecutionException\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Order matters. NumberFormatException inherits IllegalArgumentException.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mis_instance_of\u001b[0;34m(gateway, java_object, java_class)\u001b[0m\n\u001b[1;32m    462\u001b[0m             \"java_class must be a string, a JavaClass, or a JavaObject\")\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     return gateway.jvm.py4j.reflection.TypeUtil.isInstanceOf(\n\u001b[0m\u001b[1;32m    465\u001b[0m         param, java_object)\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1547\u001b[0m                     answer, self._gateway_client, self._fqn, name)\n\u001b[1;32m   1548\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1549\u001b[0;31m             raise Py4JError(\n\u001b[0m\u001b[1;32m   1550\u001b[0m                 \"{0}.{1} does not exist in the JVM\".format(self._fqn, name))\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPy4JError\u001b[0m: py4j.reflection.TypeUtil.isInstanceOf does not exist in the JVM"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}