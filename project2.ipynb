{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/26 18:37:00 WARN Utils: Your hostname, codespaces-38b548 resolves to a loopback address: 127.0.0.1; using 10.0.10.102 instead (on interface eth0)\n",
      "24/11/26 18:37:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/26 18:37:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import TimestampType\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Project2\").config(\"spark.driver.memory\", \"4g\").config(\"spark.executor.memory\", \"4g\").getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "output_dir = \"output/\"\n",
    "task2_output_total = output_dir + \"task2/task2_total.csv\"\n",
    "task2_output_avgsales = output_dir + \"task2/task2_avgsales.csv\"\n",
    "task2_output_season = output_dir + \"task2/task2_season.csv\"\n",
    "task3_output = output_dir + \"task3/task3.csv\"\n",
    "task4_output = output_dir + \"task4/task4.csv\"\n",
    "\n",
    "checkpoint_dir = \"checkpoint/task5/\"\n",
    "task5_output = output_dir + \"task5.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------------+--------------------+\n",
      "|      asin|helpful|      main_image_url|       product_title|            sentence|\n",
      "+----------+-------+--------------------+--------------------+--------------------+\n",
      "|B000AO3L84|    1.7|http://ecx.images...|Canon 430EX Speed...|this flash is a s...|\n",
      "|B001SEQPGK|    1.3|http://ecx.images...|Sony Cyber-shot D...|The pictures were...|\n",
      "|0553386697|    1.9|http://ecx.images...|The Whole-Brain C...|A very good resou...|\n",
      "|B006SUWZH2|   0.25|http://ecx.images...|Memorex Portable ...|We have it in a c...|\n",
      "|B000W7F5SS|    0.9|http://ecx.images...|Harry Potter and ...|Again the makers ...|\n",
      "|B000AO3L84|    2.0|http://ecx.images...|Canon 430EX Speed...|This flash is a g...|\n",
      "|B00081NX5U|   0.73|http://ecx.images...|iPod Detachable R...|So I've had these...|\n",
      "|B00000F1D3|    0.9|http://ecx.images...|             Believe|they're cd's or t...|\n",
      "|B00000FCBH|    1.3|http://ecx.images...|  2Pac Greatest Hits|he proved that ev...|\n",
      "|B00013M6NU|    0.4|http://ecx.images...|Nikon MH-61 Batte...|I realize these t...|\n",
      "|0375703764|    1.5|http://ecx.images...|     House of Leaves|Emulate contortio...|\n",
      "|B000002GJH|    0.9|http://ecx.images...|   Temple Of The Dog|The best tracks i...|\n",
      "|B002JSM3KQ|    0.2|http://ecx.images...|Monopoly Board Ga...|, so Amazon likes...|\n",
      "|B008FSCNTK|    0.4|http://ecx.images...|       Glad Rag Doll|but I'll be check...|\n",
      "|B003T90WY8|    1.7|http://ecx.images...|EARBUDi Clips on ...|Edit to add: Thes...|\n",
      "|B00002E220|    0.8|http://ecx.images...|  Last of the Dogmen|I had the VHS and...|\n",
      "|B0002COTDA|    1.0|http://ecx.images...|Columbo - The Com...|Columbo is one of...|\n",
      "|0061208493|   1.36|http://ecx.images...|The Complete C. S...|any of his books ...|\n",
      "|B000002KB8|    1.0|http://ecx.images...|       Black Sabbath|The title has not...|\n",
      "|0470474874|    1.1|http://ecx.images...|    Excel 2010 Bible|It basically copi...|\n",
      "+----------+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainreview_df = spark.read.json(\"train.json\")\n",
    "reviews_df = spark.read.json(\"test.json\")\n",
    "trainreview_df.show()\n",
    "\n",
    "trainreview_df = trainreview_df.withColumn(\"helpful\", F.col(\"helpful\").cast(\"double\"))\n",
    "#trainreview_df.printSchema()\n",
    "\n",
    "reviews_df = reviews_df.withColumn(\"helpful\", F.col(\"helpful\").cast(\"double\"))\n",
    "#reviwes_df.printSchema()\n",
    "#print(reviwes_df.describe())\n",
    "# Check if any rows have nulls in the 'helpful' column after casting\n",
    "#invalid_rows = reviwes_df.filter(F.col(\"sentence\").isNull())\n",
    "# Show rows that could not be cast to double\n",
    "#invalid_rows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------------+--------------------+\n",
      "|      asin|helpful|      main_image_url|       product_title|            sentence|\n",
      "+----------+-------+--------------------+--------------------+--------------------+\n",
      "|B00VG90446|   1.07|http://ecx.images...|Flexion KS-902 Ki...|so it stays in pl...|\n",
      "|B001196MG0|   1.33|http://ecx.images...|Savage 107X12-1 S...|Love this seamles...|\n",
      "|B00081NX5U|   1.17|http://ecx.images...|iPod Detachable R...|very happy with m...|\n",
      "|B003HC9JIW|    1.6|http://ecx.images...|Start! Walking At...|Even for someone ...|\n",
      "|B00C30FCUI|   1.49|http://ecx.images...|Symphonized NRG P...|, those have alwa...|\n",
      "|B001196MG0|   1.47|http://ecx.images...|Savage 107X12-1 S...|but after a year ...|\n",
      "|B00AR1G3FS|   1.24|http://ecx.images...|Farewell Live Fro...|While not quite a...|\n",
      "|B007R3AZNK|   0.67|http://ecx.images...|Driving Towards T...|Until now, Sloe G...|\n",
      "|0761165975|    1.0|http://ecx.images...|The Wedding Plann...|I considered the ...|\n",
      "|B00000FCBH|   0.03|http://ecx.images...|  2Pac Greatest Hits|\"Baby, don't cry,...|\n",
      "|B000HKDE7Y|   0.74|http://ecx.images...|Struggle From The...|I'm glad I bought...|\n",
      "|B00081NX5U|   1.59|http://ecx.images...|iPod Detachable R...|Great sound I bou...|\n",
      "|0451232852|    0.5|http://ecx.images...|Fall of Giants: B...|The Age of Enligh...|\n",
      "|B000AO3L84|   1.66|http://ecx.images...|Canon 430EX Speed...|When you take pic...|\n",
      "|B000002IAO|   0.75|http://ecx.images...|  In-A-Gadda-Da-Vida|There were times ...|\n",
      "|B000002GJH|   0.37|http://ecx.images...|   Temple Of The Dog|Grunge can't just...|\n",
      "|0671015206|   1.03|http://ecx.images...|The Millionaire N...|Worth Skipping, o...|\n",
      "|0670012335|   0.31|http://ecx.images...|Llama Llama Time ...|This was a Christ...|\n",
      "|B0019FHM9M|   0.39|http://ecx.images...|Lowpricenice MH20...|-----------------...|\n",
      "|0399162089|   1.13|http://ecx.images...|Outside the Lines...|I couldn't make t...|\n",
      "+----------+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "online_retail_df = spark.read.csv(\"Online-Retail.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|        0|        0|       1454|       0|          0|        0|    135080|      0|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "online_retail_df.select([F.count(F.when(col(c).isNull(), c)).alias(c) for c in online_retail_df.columns]).show()\n",
    "\n",
    "# Drop rows with nulls in important columns like CustomerID, Description, etc.\n",
    "online_retail_df = online_retail_df.dropna(subset=[\"CustomerID\", \"Description\", \"InvoiceDate\", \"Quantity\", \"UnitPrice\"])\n",
    "#online_retail_df.select([F.count(F.when(col(c).isNull(), c)).alias(c) for c in online_retail_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "online_retail_df = online_retail_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast the invoice date to timestamp\n",
    "online_retail_df = online_retail_df.withColumn(\"InvoiceDate\", F.to_timestamp(\"InvoiceDate\", \"M/d/yyyy H:mm\"))\n",
    "online_retail_df = online_retail_df.withColumn(\"InvoiceDate\", F.col(\"InvoiceDate\").cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|  C538350|   85099F|JUMBO BAG STRAWBERRY|      -2|2010-12-10 15:01:00|     1.65|     13798|United Kingdom|\n",
      "|  C538375|    22220|CAKE STAND LOVEBI...|      -1|2010-12-12 11:19:00|     9.95|     17126|United Kingdom|\n",
      "|  C539726|    22791|T-LIGHT GLASS FLU...|     -10|2010-12-21 14:24:00|     1.25|     17007|United Kingdom|\n",
      "|  C540307|    22084|PAPER CHAIN KIT E...|     -36|2011-01-06 12:58:00|     2.95|     15823|United Kingdom|\n",
      "|  C542138|    20866|BLUE ROSE FABRIC ...|    -120|2011-01-25 17:21:00|     1.06|     17368|United Kingdom|\n",
      "|  C543347|    22629| SPACEBOY LUNCH BOX |      -1|2011-02-07 12:44:00|     1.95|     12472|       Germany|\n",
      "|  C544830|    22059|CERAMIC STRAWBERR...|      -6|2011-02-24 09:59:00|     1.49|     13118|United Kingdom|\n",
      "|  C545456|    21527|RED RETROSPOT TRA...|      -1|2011-03-02 17:15:00|     7.95|     17865|United Kingdom|\n",
      "|  C545773|    21843|RED RETROSPOT CAK...|      -1|2011-03-07 12:06:00|    10.95|     17139|United Kingdom|\n",
      "|  C546168|    22892|SET OF SALT AND P...|     -12|2011-03-10 10:22:00|     1.25|     16670|United Kingdom|\n",
      "|  C546511|    22801|ANTIQUE GLASS PED...|      -1|2011-03-14 12:19:00|     3.75|     12921|United Kingdom|\n",
      "|  C548015|    82583|HOT BATHS METAL SIGN|     -30|2011-03-29 11:30:00|     1.69|     13802|United Kingdom|\n",
      "|  C548187|    22423|REGENCY CAKESTAND...|      -1|2011-03-29 15:06:00|    12.75|     17511|United Kingdom|\n",
      "|  C542642|    22720|SET OF 3 CAKE TIN...|      -1|2011-01-31 11:27:00|     4.95|     15827|United Kingdom|\n",
      "|  C543175|     POST|             POSTAGE|      -1|2011-02-04 09:46:00|     18.0|     12712|       Germany|\n",
      "|  C543918|    71459|HANGING JAM JAR T...|      -5|2011-02-14 13:42:00|     0.85|     12921|United Kingdom|\n",
      "|  C544655|    37447|CERAMIC CAKE DESI...|      -5|2011-02-22 12:57:00|     1.49|     13113|United Kingdom|\n",
      "|  C546730|    21937|STRAWBERRY   PICN...|      -2|2011-03-16 11:39:00|     2.95|     18183|United Kingdom|\n",
      "|  C547930|     POST|             POSTAGE|      -1|2011-03-28 14:00:00|     18.0|     12594|         Italy|\n",
      "|  C548454|        M|              Manual|      -1|2011-03-31 11:42:00|     57.6|     16422|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#check for outliers\n",
    "online_retail_df.filter((col(\"Quantity\") < 0) | (col(\"UnitPrice\") < 0)).show()\n",
    "\n",
    "# Drop rows where Quantity or UnitPrice are negative (common outlier check)\n",
    "online_retail_df = online_retail_df.filter((F.col(\"Quantity\") >= 0) & (F.col(\"UnitPrice\") >= 0))\n",
    "#online_retail_df.filter((col(\"Quantity\") < 0) | (col(\"UnitPrice\") < 0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize for consistent description characters\n",
    "online_retail_df = online_retail_df.withColumn(\"Description\", F.upper(F.col(\"Description\")))\n",
    "\n",
    "#handle special cases in case for better performance for MLlib\n",
    "#online_retail_df = online_retail_df.filter(~F.col(\"InvoiceNo\").startswith(\"C\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|     13047|United Kingdom|\n",
      "|   536368|    22960|JAM MAKING SET WI...|       6|2010-12-01 08:34:00|     4.25|     13047|United Kingdom|\n",
      "|   536388|    22915|ASSORTED BOTTLE T...|      12|2010-12-01 09:59:00|     0.42|     16250|United Kingdom|\n",
      "|   536401|    21464|DISCO BALL ROTATO...|       1|2010-12-01 11:21:00|     4.25|     15862|United Kingdom|\n",
      "|   536412|    22569|FELTCRAFT CUSHION...|       2|2010-12-01 11:49:00|     3.75|     17920|United Kingdom|\n",
      "|   536425|    22645|CERAMIC HEART FAI...|      12|2010-12-01 12:08:00|     1.45|     13758|United Kingdom|\n",
      "|   536488|    22376|AIRLINE BAG VINTA...|       1|2010-12-01 12:31:00|     4.25|     17897|United Kingdom|\n",
      "|   536520|    21930|JUMBO STORAGE BAG...|       1|2010-12-01 12:43:00|     1.95|     14729|United Kingdom|\n",
      "|   536534|    22866|HAND WARMER SCOTT...|      12|2010-12-01 13:33:00|      2.1|     15350|United Kingdom|\n",
      "|   536540|   85136A|YELLOW SHARK HELI...|       2|2010-12-01 14:05:00|     7.95|     14911|          EIRE|\n",
      "|   536562|   79302M|ART LIGHTS,FUNK M...|       6|2010-12-01 15:08:00|     2.95|     13468|United Kingdom|\n",
      "|   536569|    22941|CHRISTMAS LIGHTS ...|       1|2010-12-01 15:35:00|      8.5|     16274|United Kingdom|\n",
      "|   536571|    21352|EUCALYPTUS & PINE...|       2|2010-12-01 15:37:00|     6.75|     14696|United Kingdom|\n",
      "|   536591|    21985|PACK OF 12 HEARTS...|       4|2010-12-01 16:58:00|     0.29|     14606|United Kingdom|\n",
      "|   536624|    22672|FRENCH BATHROOM S...|      12|2010-12-02 10:45:00|     1.65|     13418|United Kingdom|\n",
      "|   536624|    21843|RED RETROSPOT CAK...|       4|2010-12-02 10:45:00|    10.95|     13418|United Kingdom|\n",
      "|   536630|    22752|SET 7 BABUSHKA NE...|       2|2010-12-02 10:56:00|     7.65|     17850|United Kingdom|\n",
      "|   536635|    22441|GROW YOUR OWN BAS...|       8|2010-12-02 11:22:00|      2.1|     15955|United Kingdom|\n",
      "|   536667|    22594|CHRISTMAS GINGHAM...|      24|2010-12-02 12:09:00|     0.85|     15260|United Kingdom|\n",
      "|   536671|    22740|        POLKADOT PEN|      48|2010-12-02 12:10:00|     0.85|     13305|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "online_retail_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----+----+------------------+\n",
      "|StockCode|         Description|Month|Year|        TotalSales|\n",
      "+---------+--------------------+-----+----+------------------+\n",
      "|    22692|DOORMAT WELCOME T...|    4|2011|             512.7|\n",
      "|    22384|LUNCH BAG PINK PO...|    1|2011|            902.15|\n",
      "|    21221|SET/4 BADGES CUTE...|    2|2011|             43.75|\n",
      "|    22114|HOT WATER BOTTLE ...|   12|2010|1863.0500000000002|\n",
      "|    22236|CAKE STAND 3 TIER...|    1|2011|403.04999999999995|\n",
      "|    85213|MINI  ZINC GARDEN...|    3|2011|44.199999999999996|\n",
      "|    22624|IVORY KITCHEN SCALES|    3|2011|            779.45|\n",
      "|    20914|SET/5 RED RETROSP...|    3|2011| 962.6500000000001|\n",
      "|    21051|      RIBBONS PURSE |   12|2010|              33.6|\n",
      "|    21989|PACK OF 20 SKULL ...|    1|2011|115.59999999999998|\n",
      "|    21615|4 LAVENDER BOTANI...|    1|2011|             165.0|\n",
      "|    22807|SET OF 6 T-LIGHTS...|   12|2010|141.60000000000002|\n",
      "|    21888|           BINGO SET|    2|2011|             127.5|\n",
      "|   84531B|BLUE KNITTED EGG ...|    3|2011|40.949999999999996|\n",
      "|    22026|BANQUET BIRTHDAY ...|    2|2011|             66.24|\n",
      "|    22976|CIRCUS PARADE CHI...|    2|2011|             98.75|\n",
      "|    22079|RIBBON REEL HEART...|    3|2011|             211.2|\n",
      "|    22781|GUMBALL MAGAZINE ...|   12|2010|            267.75|\n",
      "|    22474|SPACEBOY TV DINNE...|    3|2011|59.400000000000006|\n",
      "|    21967|PACK OF 12 SKULL ...|   12|2010| 92.50999999999999|\n",
      "+---------+--------------------+-----+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#-----------------------------------\n",
    "#Task 2: Sales Data Aggregation and Feature Engineering\n",
    "#-----------------------------------\n",
    "#total sales per product per month\n",
    "#get the month and year from invoicedate\n",
    "online_retail_df = online_retail_df.withColumn(\"Month\", F.month(\"InvoiceDate\")).withColumn(\"Year\", F.year(\"InvoiceDate\"))\n",
    "\n",
    "#make a revenue column, total quantity * price\n",
    "online_retail_df = online_retail_df.withColumn(\"Revenue\", col(\"Quantity\") * col(\"UnitPrice\"))\n",
    "\n",
    "#total sales per product and month. calculated by summing total quantity * price\n",
    "total_sales_df = online_retail_df.groupBy(\"StockCode\", \"Description\", \"Month\", \"Year\").agg(F.sum(\"Revenue\").alias(\"TotalSales\"))\n",
    "total_sales_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Sales Data Aggregation and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerID|    AverageRevenue|\n",
      "+----------+------------------+\n",
      "|     12346|           77183.6|\n",
      "|     16446|           56157.5|\n",
      "|     15098|           13305.5|\n",
      "|     15749|           4453.43|\n",
      "|     15195|            3861.0|\n",
      "|     13135|            3096.0|\n",
      "|     17846|            2033.1|\n",
      "|     18087|2027.8599999999997|\n",
      "|     16532|1687.1999999999998|\n",
      "|     16000|1377.0777777777776|\n",
      "|     16754|            1001.2|\n",
      "|     12755| 952.9874999999998|\n",
      "|     18133| 931.4999999999999|\n",
      "|     12798| 872.1299999999999|\n",
      "|     17949|           835.864|\n",
      "|     17553|             743.8|\n",
      "|     15299| 643.8585714285715|\n",
      "|     16308|             640.0|\n",
      "|     16986|             624.4|\n",
      "|     18080|            615.75|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#average revenue per customer\n",
    "#get average revnue for each customer id\n",
    "avg_revnue_df = online_retail_df.groupBy(\"CustomerID\").agg(F.avg(\"Revenue\").alias(\"AverageRevenue\")).orderBy(F.desc(\"AverageRevenue\"))\n",
    "avg_revnue_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----+------------------+\n",
      "|StockCode|         Description|Month|      MonthlySales|\n",
      "+---------+--------------------+-----+------------------+\n",
      "|   85123A|WHITE HANGING HEA...|    4| 9581.650000000001|\n",
      "|    84879|ASSORTED COLOUR B...|    1|2704.1899999999996|\n",
      "|    23166|MEDIUM CERAMIC TO...|    9|            397.26|\n",
      "|    47566|       PARTY BUNTING|    1|1815.1499999999999|\n",
      "|        M|              MANUAL|    8|           2989.54|\n",
      "|   85123A|WHITE HANGING HEA...|    2|4912.6500000000015|\n",
      "|   85099B|JUMBO BAG RED RET...|   10| 9763.060000000001|\n",
      "|    22423|REGENCY CAKESTAND...|    1|10765.499999999998|\n",
      "|   85099B|JUMBO BAG RED RET...|    7|5654.5999999999985|\n",
      "|     POST|             POSTAGE|   11|          10349.95|\n",
      "|    47566|       PARTY BUNTING|   11|3715.7099999999996|\n",
      "|   85123A|WHITE HANGING HEA...|   11|13849.929999999997|\n",
      "|    47566|       PARTY BUNTING|    9| 4386.999999999998|\n",
      "|     POST|             POSTAGE|    2|            3166.0|\n",
      "|        M|              MANUAL|   12|            666.27|\n",
      "|   85123A|WHITE HANGING HEA...|    8| 5498.100000000001|\n",
      "|    84879|ASSORTED COLOUR B...|    3|3997.9799999999996|\n",
      "|    47566|       PARTY BUNTING|    8|           6306.05|\n",
      "|    22423|REGENCY CAKESTAND...|    6| 8216.349999999999|\n",
      "|    84879|ASSORTED COLOUR B...|    5| 4977.239999999999|\n",
      "+---------+--------------------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#seasonal patterns for top selling products\n",
    "#get products by stock code and their highest total revnue as sum\n",
    "top_products_df = online_retail_df.groupBy(\"StockCode\").agg(F.sum(\"Revenue\").alias(\"TotalRevenue\")).orderBy(F.desc(\"TotalRevenue\"))\n",
    "    \n",
    "#join with df to get montly data, group by product and month for each of their total revenue\n",
    "seasonal_pattern = online_retail_df.join(top_products_df.limit(10), \"StockCode\").groupBy(\"StockCode\", \"Description\", \"Month\").agg(F.sum(\"Revenue\").alias(\"MonthlySales\"))\n",
    "seasonal_pattern.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------------------+\n",
      "|CustomerID|StockCode|CustomerLifetimeValue|\n",
      "+----------+---------+---------------------+\n",
      "|     15363|    22382|                 16.5|\n",
      "|     17235|   85184C|   35.400000000000006|\n",
      "|     17454|    21931|                 19.5|\n",
      "|     13113|    22423|                700.8|\n",
      "|     14498|    22457|                 11.8|\n",
      "|     15059|    21175|   49.199999999999996|\n",
      "|     13198|    20751|   25.200000000000003|\n",
      "|     16609|    22969|                 34.8|\n",
      "|     15719|    22411|                47.19|\n",
      "|     16992|    22500|                 19.8|\n",
      "|     12668|    23078|                 30.0|\n",
      "|     14298|    22608|               157.32|\n",
      "|     13081|    22132|   30.599999999999998|\n",
      "|     15129|    22360|   35.400000000000006|\n",
      "|     14156|    22113|                  7.5|\n",
      "|     15529|    10002|   15.299999999999999|\n",
      "|     13506|    84077|   13.919999999999998|\n",
      "|     18116|    21381|                 5.07|\n",
      "|     17406|    22795|                 13.5|\n",
      "|     17863|    22560|                 30.0|\n",
      "+----------+---------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#customer liftime value: total revenue per customer\n",
    "clv_df = online_retail_df.groupBy(\"CustomerID\", \"StockCode\").agg(F.sum(\"Revenue\").alias(\"CustomerLifetimeValue\"))\n",
    "clv_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+\n",
      "|StockCode|PopularityScore|\n",
      "+---------+---------------+\n",
      "|    21889|            449|\n",
      "|    21259|            237|\n",
      "|    22728|            613|\n",
      "|    21452|            133|\n",
      "|    21894|             71|\n",
      "|    22121|            114|\n",
      "|    21248|             52|\n",
      "|    22254|             41|\n",
      "|    21249|             79|\n",
      "|    90143|              7|\n",
      "|    22596|            234|\n",
      "|    84881|              5|\n",
      "|    23318|            329|\n",
      "|    23459|             19|\n",
      "|    21331|              7|\n",
      "|   90210B|              6|\n",
      "|    20868|             31|\n",
      "|    23843|              1|\n",
      "|    22314|             93|\n",
      "|    21535|            310|\n",
      "+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#product popularity: counted by unique transaction made under each stock code\n",
    "product_popularity = online_retail_df.groupBy(\"StockCode\").agg(F.countDistinct(\"InvoiceNo\").alias(\"PopularityScore\"))\n",
    "product_popularity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+\n",
      "|StockCode|PopularityScore|\n",
      "+---------+---------------+\n",
      "|    21889|          449.0|\n",
      "|    21259|          237.0|\n",
      "|    22728|          613.0|\n",
      "|    21452|          133.0|\n",
      "|    21894|           71.0|\n",
      "|    22121|          114.0|\n",
      "|    21248|           52.0|\n",
      "|    22254|           41.0|\n",
      "|    21249|           79.0|\n",
      "|    90143|            7.0|\n",
      "|    22596|          234.0|\n",
      "|    84881|            5.0|\n",
      "|    23318|          329.0|\n",
      "|    23459|           19.0|\n",
      "|    21331|            7.0|\n",
      "|   90210B|            6.0|\n",
      "|    20868|           31.0|\n",
      "|    23843|            1.0|\n",
      "|    22314|           93.0|\n",
      "|    21535|          310.0|\n",
      "+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "product_popularity = product_popularity.withColumn(\"PopularityScore\", F.col(\"PopularityScore\").cast(DoubleType()))\n",
    "product_popularity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 66:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------------------+\n",
      "|StockCode|Season|     SeasonalSales|\n",
      "+---------+------+------------------+\n",
      "|    21110|Winter|            1349.3|\n",
      "|    22668|Winter|            1411.7|\n",
      "|    22966|Winter|2459.8599999999997|\n",
      "|   90002D|Winter|              30.0|\n",
      "|    37446|Winter| 659.5999999999998|\n",
      "|    22252|Spring|             97.94|\n",
      "|    22760|Winter| 849.8999999999999|\n",
      "|   84558A|Winter|268.45000000000005|\n",
      "|    22149|Spring| 2487.700000000001|\n",
      "|    22421|Winter|            159.48|\n",
      "|    22301|Winter|1107.4500000000003|\n",
      "|    22537|Spring|            190.26|\n",
      "|    22107|Winter|            448.74|\n",
      "|    21564|Spring|430.70000000000005|\n",
      "|   84575A|Winter|              5.95|\n",
      "|   84952C|Spring|              30.0|\n",
      "|   15056P|Winter|             708.7|\n",
      "|    22452|Winter|            520.25|\n",
      "|    84818|Winter|             408.0|\n",
      "|    21463|Spring|382.65000000000003|\n",
      "+---------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#seasonal trends:\n",
    "#make season column based on month\n",
    "online_retail_df = online_retail_df.withColumn(\"Season\",\n",
    "                    F.when(col(\"Month\").isin(12, 1, 2), \"Winter\") #if month is in one of these numbers\n",
    "                    .when(col(\"Month\").isin(3, 4, 5), \"Spring\")\n",
    "                    .when(col(\"Month\").isin(6, 7, 8), \"Summer\")\n",
    "                    .when(col(\"Month\").isin(9, 10, 11), \"Fall\")\n",
    "                    )\n",
    "    \n",
    "#total revenue of each product and season\n",
    "seasonal_trends = online_retail_df.groupBy(\"StockCode\", \"Season\").agg(F.sum(\"Revenue\").alias(\"SeasonalSales\"))\n",
    "seasonal_trends.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the aggregated data to the directory as csv files\n",
    "#try:\n",
    "#    total_sales_df.write.csv(task2_output_total, header=True)\n",
    "#    avg_revnue_df.write.csv(task2_output_avgsales, header=True)\n",
    "#    seasonal_pattern.write.csv(task2_output_season, header=True)\n",
    "#except ValueError as e:\n",
    "#    print(f\"error {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Demand Forecasting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join features into a consolidated DataFrame\n",
    "forecasting_df = total_sales_df.join(clv_df, \"StockCode\", \"left\") \\\n",
    "                               .join(product_popularity, \"StockCode\", \"left\") \\\n",
    "                               .join(seasonal_trends, \"StockCode\", \"left\")\n",
    "\n",
    "# Fill nulls with 0 or appropriate values for ML training\n",
    "forecasting_df = forecasting_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 98:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----+----+----------+----------+---------------------+---------------+------+-----------------+-----------+------------+\n",
      "|StockCode|         Description|Month|Year|TotalSales|CustomerID|CustomerLifetimeValue|PopularityScore|Season|    SeasonalSales|Lag_1_Month|Lag_2_Months|\n",
      "+---------+--------------------+-----+----+----------+----------+---------------------+---------------+------+-----------------+-----------+------------+\n",
      "|   10123C|HEARTS WRAPPING T...|   12|2010|      0.65|     17967|                 0.65|            3.0|Winter|             0.65|       0.65|        0.65|\n",
      "|   10123C|HEARTS WRAPPING T...|   12|2010|      0.65|     17967|                 0.65|            3.0|Spring|              2.6|       0.65|        0.65|\n",
      "|   10123C|HEARTS WRAPPING T...|   12|2010|      0.65|     14670|   1.9500000000000002|            3.0|Winter|             0.65|       0.65|        0.65|\n",
      "|   10123C|HEARTS WRAPPING T...|   12|2010|      0.65|     14670|   1.9500000000000002|            3.0|Spring|              2.6|       0.65|        0.65|\n",
      "|   10123C|HEARTS WRAPPING T...|    3|2011|       2.6|     14064|                 0.65|            3.0|Winter|             0.65|       0.65|        0.65|\n",
      "|   10123C|HEARTS WRAPPING T...|    3|2011|       2.6|     14064|                 0.65|            3.0|Spring|              2.6|        2.6|        0.65|\n",
      "|   10123C|HEARTS WRAPPING T...|    3|2011|       2.6|     17967|                 0.65|            3.0|Winter|             0.65|        2.6|         2.6|\n",
      "|   10123C|HEARTS WRAPPING T...|    3|2011|       2.6|     17967|                 0.65|            3.0|Spring|              2.6|        2.6|         2.6|\n",
      "|   10123C|HEARTS WRAPPING T...|    3|2011|       2.6|     14670|   1.9500000000000002|            3.0|Winter|             0.65|        2.6|         2.6|\n",
      "|   10123C|HEARTS WRAPPING T...|    3|2011|       2.6|     14670|   1.9500000000000002|            3.0|Spring|              2.6|        2.6|         2.6|\n",
      "|    10133|COLOURING PENCILS...|   12|2010|     78.75|     16841|                  8.4|          122.0|Summer|743.2800000000002|      78.75|       78.75|\n",
      "|    10133|COLOURING PENCILS...|   12|2010|     78.75|     16841|                  8.4|          122.0|Winter|            152.3|      78.75|       78.75|\n",
      "|    10133|COLOURING PENCILS...|   12|2010|     78.75|     16706|                 0.84|          122.0|  Fall|            81.06|      78.75|       78.75|\n",
      "|    10133|COLOURING PENCILS...|   12|2010|     78.75|     16706|                 0.84|          122.0|Spring|           162.35|      78.75|       78.75|\n",
      "|    10133|COLOURING PENCILS...|   12|2010|     78.75|     16706|                 0.84|          122.0|Summer|743.2800000000002|      78.75|       78.75|\n",
      "|    10133|COLOURING PENCILS...|   12|2010|     78.75|     16706|                 0.84|          122.0|Winter|            152.3|      78.75|       78.75|\n",
      "|    10133|COLOURING PENCILS...|   12|2010|     78.75|     14132|   50.400000000000006|          122.0|  Fall|            81.06|      78.75|       78.75|\n",
      "|    10133|COLOURING PENCILS...|   12|2010|     78.75|     14132|   50.400000000000006|          122.0|Spring|           162.35|      78.75|       78.75|\n",
      "|    10133|COLOURING PENCILS...|   12|2010|     78.75|     14132|   50.400000000000006|          122.0|Summer|743.2800000000002|      78.75|       78.75|\n",
      "|    10133|COLOURING PENCILS...|   12|2010|     78.75|     14132|   50.400000000000006|          122.0|Winter|            152.3|      78.75|       78.75|\n",
      "+---------+--------------------+-----+----+----------+----------+---------------------+---------------+------+-----------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create lag features using window functions\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "windowSpec = Window.partitionBy(\"StockCode\").orderBy(\"Year\", \"Month\")\n",
    "forecasting_df = forecasting_df.withColumn(\"Lag_1_Month\", F.lag(\"TotalSales\", 1).over(windowSpec))\n",
    "forecasting_df = forecasting_df.withColumn(\"Lag_2_Months\", F.lag(\"TotalSales\", 2).over(windowSpec))\n",
    "\n",
    "# Drop rows with null values created by lags\n",
    "forecasting_df = forecasting_df.na.drop()\n",
    "\n",
    "# Display the consolidated DataFrame structure\n",
    "forecasting_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- TotalSales: double (nullable = false)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- CustomerLifetimeValue: double (nullable = false)\n",
      " |-- PopularityScore: double (nullable = false)\n",
      " |-- Season: string (nullable = true)\n",
      " |-- SeasonalSales: double (nullable = false)\n",
      " |-- Lag_1_Month: double (nullable = true)\n",
      " |-- Lag_2_Months: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forecasting_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 125:============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----+----+----------+----------+---------------------+---------------+------+-------------+-----------+------------+\n",
      "|StockCode|Description|Month|Year|TotalSales|CustomerID|CustomerLifetimeValue|PopularityScore|Season|SeasonalSales|Lag_1_Month|Lag_2_Months|\n",
      "+---------+-----------+-----+----+----------+----------+---------------------+---------------+------+-------------+-----------+------------+\n",
      "|        0|          0|    0|   0|         0|         0|                    0|              0|     0|            0|          0|           0|\n",
      "+---------+-----------+-----+----+----------+----------+---------------------+---------------+------+-------------+-----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "forecasting_df.select([F.count(F.when(col(c).isNull(), c)).alias(c) for c in forecasting_df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorAssembler_1522a6d429bd\n",
      "StandardScaler_847cbcfd6154\n",
      "LinearRegression_0e557a479917\n"
     ]
    }
   ],
   "source": [
    "# Assemble feature columns\n",
    "feature_cols = [\"Lag_1_Month\", \"Lag_2_Months\", \"CustomerLifetimeValue\", \"PopularityScore\", \"SeasonalSales\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "# Initialize the regression model (e.g., Linear Regression)\n",
    "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"TotalSales\")\n",
    "\n",
    "# Create a pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, scaler, lr])\n",
    "\n",
    "for stage in pipeline.getStages():\n",
    "    print(stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with mismatching data types\n",
    "for column_name in feature_cols + [\"TotalSales\"]:\n",
    "    forecasting_df = forecasting_df.withColumn(column_name, forecasting_df[column_name].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- TotalSales: double (nullable = false)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- CustomerLifetimeValue: double (nullable = false)\n",
      " |-- PopularityScore: double (nullable = false)\n",
      " |-- Season: string (nullable = true)\n",
      " |-- SeasonalSales: double (nullable = false)\n",
      " |-- Lag_1_Month: double (nullable = true)\n",
      " |-- Lag_2_Months: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forecasting_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train_data, test_data = forecasting_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN, infinite, and null values with 0\n",
    "for column in feature_cols + [\"TotalSales\"]:\n",
    "    train_data = train_data.withColumn(\n",
    "        column,\n",
    "        F.when(\n",
    "            col(column).isNull() |\n",
    "            (col(column) == float(\"inf\")) |\n",
    "            (col(column) == float(\"-inf\")),\n",
    "            0\n",
    "        ).otherwise(col(column))\n",
    "    )\n",
    "    \n",
    "for column in feature_cols + [\"TotalSales\"]:\n",
    "    test_data = test_data.withColumn(\n",
    "        column,\n",
    "        F.when(\n",
    "            col(column).isNull() |\n",
    "            (col(column) == float(\"inf\")) |\n",
    "            (col(column) == float(\"-inf\")),\n",
    "            0\n",
    "        ).otherwise(col(column))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/26 17:55:36 WARN Instrumentation: [5e0d3608] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/11/26 17:55:43 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/11/26 17:55:43 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "24/11/26 17:55:50 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "[Stage 323:============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 36.13037456093392\n",
      "Root Squared Error (RMSE): 0.9994526911583858\n",
      "Mean Absolute Error (MAE): 0.829770257686961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit the model\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator_rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=\"TotalSales\", predictionCol=\"prediction\")\n",
    "evaluator_r2 = RegressionEvaluator(metricName=\"r2\", labelCol=\"TotalSales\", predictionCol=\"prediction\")\n",
    "evaluator_mae = RegressionEvaluator(metricName=\"mae\", labelCol=\"TotalSales\", predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Root Squared Error (RMSE): {r2}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1143:============================>                           (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned RMSE: 36.13227463764006\n",
      "Tuned R2: 0.9994526335915247\n",
      "Tuned MAE: 0.8381268927908918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Build the parameter grid for tuning\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.maxIter, [50, 100]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "# Initialize CrossValidator\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator_rmse,\n",
    "                          numFolds=3)\n",
    "\n",
    "# Run cross-validation and choose the best set of parameters\n",
    "cv_model = crossval.fit(train_data)\n",
    "\n",
    "# Make predictions with the best model\n",
    "cv_predictions = cv_model.transform(test_data)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "rmse_cv = evaluator_rmse.evaluate(cv_predictions)\n",
    "r2_cv = evaluator_r2.evaluate(cv_predictions)\n",
    "mae_cv = evaluator_mae.evaluate(cv_predictions)\n",
    "\n",
    "print(f\"Tuned RMSE: {rmse_cv}\")\n",
    "print(f\"Tuned R2: {r2_cv}\")\n",
    "print(f\"Tuned MAE: {mae_cv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Sentiment Analysis on Customer Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+--------------------+--------------------+-----+\n",
      "|      asin|helpful|      main_image_url|       product_title|            sentence|label|\n",
      "+----------+-------+--------------------+--------------------+--------------------+-----+\n",
      "|B000AO3L84|    1.7|http://ecx.images...|Canon 430EX Speed...|this flash is a s...|    1|\n",
      "|B001SEQPGK|    1.3|http://ecx.images...|Sony Cyber-shot D...|The pictures were...|    1|\n",
      "|0553386697|    1.9|http://ecx.images...|The Whole-Brain C...|A very good resou...|    1|\n",
      "|B006SUWZH2|   0.25|http://ecx.images...|Memorex Portable ...|We have it in a c...|    0|\n",
      "|B000W7F5SS|    0.9|http://ecx.images...|Harry Potter and ...|Again the makers ...|    0|\n",
      "|B000AO3L84|    2.0|http://ecx.images...|Canon 430EX Speed...|This flash is a g...|    1|\n",
      "|B00081NX5U|   0.73|http://ecx.images...|iPod Detachable R...|So I've had these...|    0|\n",
      "|B00000F1D3|    0.9|http://ecx.images...|             Believe|they're cd's or t...|    0|\n",
      "|B00000FCBH|    1.3|http://ecx.images...|  2Pac Greatest Hits|he proved that ev...|    1|\n",
      "|B00013M6NU|    0.4|http://ecx.images...|Nikon MH-61 Batte...|I realize these t...|    0|\n",
      "|0375703764|    1.5|http://ecx.images...|     House of Leaves|Emulate contortio...|    1|\n",
      "|B000002GJH|    0.9|http://ecx.images...|   Temple Of The Dog|The best tracks i...|    0|\n",
      "|B002JSM3KQ|    0.2|http://ecx.images...|Monopoly Board Ga...|, so Amazon likes...|    0|\n",
      "|B008FSCNTK|    0.4|http://ecx.images...|       Glad Rag Doll|but I'll be check...|    0|\n",
      "|B003T90WY8|    1.7|http://ecx.images...|EARBUDi Clips on ...|Edit to add: Thes...|    1|\n",
      "|B00002E220|    0.8|http://ecx.images...|  Last of the Dogmen|I had the VHS and...|    0|\n",
      "|B0002COTDA|    1.0|http://ecx.images...|Columbo - The Com...|Columbo is one of...|    0|\n",
      "|0061208493|   1.36|http://ecx.images...|The Complete C. S...|any of his books ...|    1|\n",
      "|B000002KB8|    1.0|http://ecx.images...|       Black Sabbath|The title has not...|    0|\n",
      "|0470474874|    1.1|http://ecx.images...|    Excel 2010 Bible|It basically copi...|    1|\n",
      "+----------+-------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Add a new column 'label' based on the 'helpful' score\n",
    "classified_df = trainreview_df.withColumn(\n",
    "    \"label\",\n",
    "    when(trainreview_df[\"helpful\"] > 1, 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Show the updated DataFrame\n",
    "classified_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|asin      |sentence                                                                                                                         |filtered_words                                                                                              |ngrams                                                                                                                                                                                    |features                                                                                                                               |label|\n",
      "+----------+---------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|B000AO3L84|this flash is a superb value.                                                                                                    |[flash, superb, value.]                                                                                     |[flash superb, superb value.]                                                                                                                                                             |(109920,[84539,97306],[1.0,1.0])                                                                                                       |1    |\n",
      "|B001SEQPGK|The pictures were not sharp at all.                                                                                              |[pictures, sharp, all.]                                                                                     |[pictures sharp, sharp all.]                                                                                                                                                              |(109920,[8042,37643],[1.0,1.0])                                                                                                        |1    |\n",
      "|0553386697|A very good resource for parents.                                                                                                |[good, resource, parents.]                                                                                  |[good resource, resource parents.]                                                                                                                                                        |(109920,[50937,88811],[1.0,1.0])                                                                                                       |1    |\n",
      "|B006SUWZH2|We have it in a child's room, and will be switching it out soon.                                                                 |[child's, room,, switching, soon.]                                                                          |[child's room,, room, switching, switching soon.]                                                                                                                                         |(109920,[29669,73591,93853],[1.0,1.0,1.0])                                                                                             |0    |\n",
      "|B000W7F5SS|Again the makers are too lazy to bring in the pensieve and do an entire scene.                                                   |[makers, lazy, bring, pensieve, entire, scene.]                                                             |[makers lazy, lazy bring, bring pensieve, pensieve entire, entire scene.]                                                                                                                 |(109920,[16788,40669,59160,63043,72947],[1.0,1.0,1.0,1.0,1.0])                                                                         |0    |\n",
      "|B000AO3L84|This flash is a great value for the money.                                                                                       |[flash, great, value, money.]                                                                               |[flash great, great value, value money.]                                                                                                                                                  |(109920,[451,1213,84219],[1.0,1.0,1.0])                                                                                                |1    |\n",
      "|B00081NX5U|So I've had these speakers for three days now, bought them for my garage stereo system.                                          |[speakers, three, days, now,, bought, garage, stereo, system.]                                              |[speakers three, three days, days now,, now, bought, bought garage, garage stereo, stereo system.]                                                                                        |(109920,[192,7634,27164,30169,48058,94711,97157],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                        |0    |\n",
      "|B00000F1D3|they're cd's or tape's forget about the \"spice Girl's\" Cher's  music                                                             |[cd's, tape's, forget, \"spice, girl's\", cher's, , music]                                                    |[cd's tape's, tape's forget, forget \"spice, \"spice girl's\", girl's\" cher's, cher's ,  music]                                                                                              |(109920,[1120,12087,15620,19726,30117,43619,66456],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                      |0    |\n",
      "|B00000FCBH|he proved that even with a dysfunctional family, hard-times, and near death expierences - you can still aim high and succeed.    |[proved, even, dysfunctional, family,, hard-times,, near, death, expierences, -, still, aim, high, succeed.]|[proved even, even dysfunctional, dysfunctional family,, family, hard-times,, hard-times, near, near death, death expierences, expierences -, - still, still aim, aim high, high succeed.]|(109920,[2752,18936,27510,28558,33447,43853,82943,97968,102379,102557,103416,105992],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|1    |\n",
      "|B00013M6NU|I realize these things can happen, so I truly am hoping they will replace it.                                                    |[realize, things, happen,, truly, hoping, replace, it.]                                                     |[realize things, things happen,, happen, truly, truly hoping, hoping replace, replace it.]                                                                                                |(109920,[455,5392,15245,18203,21757,29346],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                  |0    |\n",
      "|0375703764|Emulate contortionists and like to do the same with their reading material and conspiracy theorists will probably love this book.|[emulate, contortionists, like, reading, material, conspiracy, theorists, probably, love, book.]            |[emulate contortionists, contortionists like, like reading, reading material, material conspiracy, conspiracy theorists, theorists probably, probably love, love book.]                   |(109920,[1082,2832,4598,21891,22514,69107,69892,102047,107078],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                  |1    |\n",
      "|B000002GJH|The best tracks in [[ASIN:                                                                                                       |[best, tracks, [[asin:]                                                                                     |[best tracks, tracks [[asin:]                                                                                                                                                             |(109920,[2781,99647],[1.0,1.0])                                                                                                        |0    |\n",
      "|B002JSM3KQ|, so Amazon likes to use them.                                                                                                   |[,, amazon, likes, use, them.]                                                                              |[, amazon, amazon likes, likes use, use them.]                                                                                                                                            |(109920,[744,77884,83770,103403],[1.0,1.0,1.0,1.0])                                                                                    |0    |\n",
      "|B008FSCNTK|but I'll be checking the tracks first.                                                                                           |[checking, tracks, first.]                                                                                  |[checking tracks, tracks first.]                                                                                                                                                          |(109920,[39580,78054],[1.0,1.0])                                                                                                       |0    |\n",
      "|B003T90WY8|Edit to add: These work very well with the original round Apple earbud.                                                          |[edit, add:, work, well, original, round, apple, earbud.]                                                   |[edit add:, add: work, work well, well original, original round, round apple, apple earbud.]                                                                                              |(109920,[55,13468,21909,32333,51275,80544,93261],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                        |1    |\n",
      "|B00002E220|I had the VHS and figured that it was time to get the DVD.                                                                       |[vhs, figured, time, get, dvd.]                                                                             |[vhs figured, figured time, time get, get dvd.]                                                                                                                                           |(109920,[537,2743,3038,57027],[1.0,1.0,1.0,1.0])                                                                                       |0    |\n",
      "|B0002COTDA|Columbo is one of my favorite shows, and gets 5 stars.                                                                           |[columbo, one, favorite, shows,, gets, 5, stars.]                                                           |[columbo one, one favorite, favorite shows,, shows, gets, gets 5, 5 stars.]                                                                                                               |(109920,[36,179,3087,6212,21018,97227],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                      |0    |\n",
      "|0061208493|any of his books would be a great read for young teenagers as well as adults.                                                    |[books, great, read, young, teenagers, well, adults.]                                                       |[books great, great read, read young, young teenagers, teenagers well, well adults.]                                                                                                      |(109920,[599,5161,36888,62534,70371,77269],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                  |1    |\n",
      "|B000002KB8|The title has nothing to do with the lyrics.                                                                                     |[title, nothing, lyrics.]                                                                                   |[title nothing, nothing lyrics.]                                                                                                                                                          |(109920,[14657,108171],[1.0,1.0])                                                                                                      |0    |\n",
      "|0470474874|It basically copied the Help manual.                                                                                             |[basically, copied, help, manual.]                                                                          |[basically copied, copied help, help manual.]                                                                                                                                             |(109920,[38881,71810,82217],[1.0,1.0,1.0])                                                                                             |1    |\n",
      "+----------+---------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/26 19:39:20 WARN DAGScheduler: Broadcasting large task binary with size 1764.8 KiB\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, NGram, CountVectorizer\n",
    "\n",
    "# Tokenize the sentences into words\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "tokenized_df = tokenizer.transform(classified_df)\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "filtered_df = remover.transform(tokenized_df)\n",
    "\n",
    "# Apply N-grams (bigram in this case)\n",
    "ngram = NGram(n=2, inputCol=\"filtered_words\", outputCol=\"ngrams\")\n",
    "ngram_df = ngram.transform(filtered_df)\n",
    "\n",
    "# Vectorize the n-grams for model input\n",
    "vectorizer = CountVectorizer(inputCol=\"ngrams\", outputCol=\"features\")\n",
    "vectorized_model = vectorizer.fit(ngram_df)\n",
    "vectorized_df = vectorized_model.transform(ngram_df)\n",
    "\n",
    "# Show the DataFrame after all transformations\n",
    "vectorized_df.select(\"asin\", \"sentence\", \"filtered_words\", \"ngrams\", \"features\", \"label\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/26 19:47:30 WARN DAGScheduler: Broadcasting large task binary with size 1798.8 KiB\n",
      "24/11/26 19:47:30 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:31 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:31 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:31 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:31 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:31 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:31 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:31 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:31 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:31 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:31 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:31 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:32 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:32 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:32 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:32 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:32 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:32 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:32 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:32 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:32 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:32 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n",
      "24/11/26 19:47:32 WARN DAGScheduler: Broadcasting large task binary with size 1799.6 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------+-----+----------+\n",
      "|features                                                                                                                               |label|prediction|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------+-----+----------+\n",
      "|(109920,[84539,97306],[1.0,1.0])                                                                                                       |1    |1.0       |\n",
      "|(109920,[8042,37643],[1.0,1.0])                                                                                                        |1    |1.0       |\n",
      "|(109920,[50937,88811],[1.0,1.0])                                                                                                       |1    |1.0       |\n",
      "|(109920,[29669,73591,93853],[1.0,1.0,1.0])                                                                                             |0    |0.0       |\n",
      "|(109920,[16788,40669,59160,63043,72947],[1.0,1.0,1.0,1.0,1.0])                                                                         |0    |0.0       |\n",
      "|(109920,[451,1213,84219],[1.0,1.0,1.0])                                                                                                |1    |1.0       |\n",
      "|(109920,[192,7634,27164,30169,48058,94711,97157],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                        |0    |0.0       |\n",
      "|(109920,[1120,12087,15620,19726,30117,43619,66456],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                      |0    |0.0       |\n",
      "|(109920,[2752,18936,27510,28558,33447,43853,82943,97968,102379,102557,103416,105992],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|1    |1.0       |\n",
      "|(109920,[455,5392,15245,18203,21757,29346],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                  |0    |0.0       |\n",
      "|(109920,[1082,2832,4598,21891,22514,69107,69892,102047,107078],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                  |1    |1.0       |\n",
      "|(109920,[2781,99647],[1.0,1.0])                                                                                                        |0    |0.0       |\n",
      "|(109920,[744,77884,83770,103403],[1.0,1.0,1.0,1.0])                                                                                    |0    |0.0       |\n",
      "|(109920,[39580,78054],[1.0,1.0])                                                                                                       |0    |0.0       |\n",
      "|(109920,[55,13468,21909,32333,51275,80544,93261],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                                        |1    |1.0       |\n",
      "|(109920,[537,2743,3038,57027],[1.0,1.0,1.0,1.0])                                                                                       |0    |0.0       |\n",
      "|(109920,[36,179,3087,6212,21018,97227],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                      |0    |0.0       |\n",
      "|(109920,[599,5161,36888,62534,70371,77269],[1.0,1.0,1.0,1.0,1.0,1.0])                                                                  |1    |1.0       |\n",
      "|(109920,[14657,108171],[1.0,1.0])                                                                                                      |0    |0.0       |\n",
      "|(109920,[38881,71810,82217],[1.0,1.0,1.0])                                                                                             |1    |1.0       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/26 19:47:33 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Prepare final DataFrame with 'features' and 'label'\n",
    "final_df = vectorized_df.select(\"features\", \"label\")\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", regParam=0.3)\n",
    "lr_model = lr.fit(final_df)\n",
    "\n",
    "# Make predictions\n",
    "predictionsS = lr_model.transform(final_df)\n",
    "predictionsS.select(\"features\", \"label\", \"prediction\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/26 19:39:28 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/11/26 19:39:28 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/11/26 19:39:29 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.9812\n",
      "RMSE: 0.0663\n",
      "MAE: 0.0044\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using regression metrics\n",
    "evaluator_r2S = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "evaluator_rmseS = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_maeS = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "# Calculate R2, RMSE, and MAE\n",
    "r2S = evaluator_r2S.evaluate(predictionsS)\n",
    "rmseS = evaluator_rmseS.evaluate(predictionsS)\n",
    "maeS = evaluator_maeS.evaluate(predictionsS)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(f\"R²: {r2S:.4f}\")\n",
    "print(f\"RMSE: {rmseS:.4f}\")\n",
    "print(f\"MAE: {maeS:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|      asin|   aggregate_score|\n",
      "+----------+------------------+\n",
      "|B001K5UQX0|0.7543859649122807|\n",
      "|B00004UFOO|0.7674418604651163|\n",
      "|B0006ZOV5E| 0.660377358490566|\n",
      "|B00VG90446|0.8108108108108109|\n",
      "|B003T90WY8|0.7936507936507936|\n",
      "|0064430170|0.5689655172413793|\n",
      "|0375703764|0.5488958990536278|\n",
      "|B00B0DWB62|0.6194444444444445|\n",
      "|B003G9ZQQA|0.6368421052631579|\n",
      "|0553391135|0.5168539325842697|\n",
      "|B00ITOAYOQ| 0.543859649122807|\n",
      "|B00000JZC7|0.5436893203883495|\n",
      "|B00007E7K9|0.7922077922077922|\n",
      "|B001SEQPGK|0.7575757575757576|\n",
      "|B0018QROM2|0.7147540983606557|\n",
      "|0670012335|             0.672|\n",
      "|B000002KB8|0.5329512893982808|\n",
      "|B000P0J09C|0.5067567567567568|\n",
      "|B004BFVKSQ|              0.46|\n",
      "|B00KU9LQUO| 0.693069306930693|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aggregated_scores = vectorized_df.groupBy(\"asin\").agg({\"label\": \"avg\"}).withColumnRenamed(\"avg(label)\", \"aggregate_score\")\n",
    "aggregated_scores.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
